{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory to the clustering refactor folder\n",
    "import os\n",
    "os.chdir('FILEPATH')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports the functions from other scripts\n",
    "#If you make any changes to the underlying scripts you will need to rerun the code from here for those changes to apply\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")\n",
    "\n",
    "from data_prep.subnat_data_clean import *\n",
    "from data_prep.subnat_data_import import *\n",
    "from Cluster_code.cluster_functions import *\n",
    "from yaml.loader import SafeLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read config file\n",
    "clustering_refactor_folder_path = os.path.abspath(os.path.join(os.path.realpath('__file__'), '../..'))\n",
    "config_path = f\"config.yaml\".replace(\"\\\\\", \"/\")\n",
    "with open(config_path, encoding=\"utf-8\") as f:\n",
    "    loaded_config = yaml.load(f, Loader=SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split into individual metrics\n",
    "datasets = import_data(\n",
    "    loaded_config=loaded_config,\n",
    "    cols_to_select=[\"AREACD\", \"AREANM\",\"Indicator\", \"Value\"],\n",
    "    table_name=loaded_config[\"subnational_indicators_table_name\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleans the data, including UTLA imputation and boundary changes\n",
    "for key, value in datasets.items():\n",
    "    value = clean_groups(loaded_config, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert metrics into pivoted tables, your specified data is now stored as tables['custom_metrics']\n",
    "tables = {}\n",
    "for key, value in datasets.items():\n",
    "    tables[key] = metrics_to_table(value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the max rows displayed to 500 so data can be spot checked in script\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fuction isolates the desired geography type from a specified code column in lookup file\n",
    "#This can be adapted through the lookup file to run on any geography type or subset of geography\n",
    "cluster_df = get_desired_geography(\n",
    "    loaded_config= loaded_config,\n",
    "    df= tables['custom_metrics'],\n",
    "    geography_col= \"AREACD\",\n",
    ")\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the dataset and computes pearsons correlation between all metrics\n",
    "correlation_matrix = get_correlation_matrix(df= cluster_df)\n",
    "correlation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This fucntion outputs a data frame with the winzorisation thresholds (if required) for QA and governance purposes\n",
    "thresholds = get_winsorization_thresholds(\n",
    "    df=cluster_df,\n",
    "    lower_threshold = 0.01,\n",
    "    upper_threshold = 0.99,\n",
    ")\n",
    "thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes all values below and above a certain percentile and sets it to the specified percentile threshold\n",
    "#The percentile threshold can be altered and the winzorised data is output\n",
    "cluster_df_win = winsorze(\n",
    "    df=cluster_df,\n",
    "    lower_threshold = 0.01,\n",
    "    upper_threshold = 0.99,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the winsorized data (or other data should you wish to use it) and runs the kmeans model\n",
    "#The data you wish to cluster should be specified in the metrics parameter\n",
    "#n_init specifies the number of times the model is to be run, recommended 100 for initial and 10000 for final output\n",
    "#Setting min and max k specifies the range of potential cluster numbers, the code takes longer to run for wider ranges\n",
    "#A geodataframe including clusters, the cluster centres (for radar plot) and a silouette score df are output\n",
    "cluster_geodataframe, cluster_centres, sil_score = make_clustering_model(\n",
    "    loaded_config=loaded_config,\n",
    "    metrics=cluster_df_win,\n",
    "    n_init=10000,\n",
    "    min_k=4,\n",
    "    max_k=15,\n",
    ")\n",
    "cluster_geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the geodataframe, drops geodata columns and adds an area name column to give a cluster table\n",
    "cluster_table = cluster_table(\n",
    "    loaded_config=loaded_config,\n",
    "    clusters_table=cluster_geodataframe,\n",
    ") \n",
    "cluster_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function uses the geodataframe to create a map showing the cluster of each area\n",
    "#This map is automatically saved into the output folder and can be called into the excel output at the end of the script\n",
    "cluster_map = cluster_map(\n",
    "    clusters=cluster_geodataframe, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function uses the geodataframe, the cluster centres and the dataframe containing metrics to create a radar plot\n",
    "#This plot is automatically saved into the output folder and can be called into the excel output at the end of the script\n",
    "#For models with more than 6 metrics variable names may overlap\n",
    "radar_plot = radar_plot(\n",
    "    loaded_config= loaded_config,\n",
    "    metrics= cluster_df,\n",
    "    clusters= cluster_geodataframe,\n",
    "    centres = cluster_centres,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the cluster geodataframe and creates an ITL1 pivot table based on cluster using lookups\n",
    "ITL1_table = ITL1_summary(\n",
    "    loaded_config=loaded_config,\n",
    "    clusters_table=cluster_geodataframe,\n",
    ") \n",
    "ITL1_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the cluster geodataframe and df of metrics to create a table of mean values for each variable by cluster\n",
    "#The total column in this table shows an average of the values of the the desired geographies\n",
    "#this is not the same as a UK average and should not be treated as such\n",
    "mean_table = clusters_summary_stats(\n",
    "    table_metrics= cluster_df,\n",
    "    clusters_table= cluster_geodataframe,\n",
    "    stats= \"mean\",\n",
    ")\n",
    "mean_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function takes the cluster geodataframe and df of metrics to create a table of median values for each variable by cluster\n",
    "#The total column in this table shows an average of the values of the the desired geographies\n",
    "#this is not the same as a UK average and should not be treated as such\n",
    "median_table = clusters_summary_stats(\n",
    "    table_metrics= cluster_df,\n",
    "    clusters_table= cluster_geodataframe,\n",
    "    stats= \"median\",\n",
    ")\n",
    "median_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function exports all relevant data to a single xlsx file in the outputs folder\n",
    "#Including the visualisations can be specified by the boolean operator\n",
    "#If not all data is required, use frames parameter to specify desired sheets.\n",
    "#File path and file name must be specified, \n",
    "#the final \"/\" at the end of the file path and \".xlsx\" file type in the file name must not be included or it won't work\n",
    "export_to_xlsx(\n",
    "    frames = {'Cluster_table': cluster_table, 'ITL1_table': ITL1_table,\n",
    "         'Silhoutte_score': sil_score, 'Cluster_medians': median_table, 'Cluster_means': mean_table,\n",
    "         'correlation_matrix': correlation_matrix,'data': cluster_df, 'winsorized_data':cluster_df_win},\n",
    "    file_path = \"FILEPATH\",\n",
    "    file_name = \"FILENAME\",\n",
    "    include_maps = True,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
