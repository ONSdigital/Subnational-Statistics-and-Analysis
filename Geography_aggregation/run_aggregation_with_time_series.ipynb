{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory to the aggregation code folder, path does not require \"/\" at the end\n",
    "import os\n",
    "os.chdir('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in required packages\n",
    "import yaml\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from yaml.loader import SafeLoader\n",
    "import sys\n",
    "sys.path.insert(1, \"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in config from the aggregation code folder, the config contains information on file path and field names\n",
    "#the config must be updated and saved each time the inputs to the notebook change\n",
    "clustering_refactor_folder_path = os.path.abspath(os.path.join(os.path.realpath('__file__'), '../..'))\n",
    "config_path = f\"config.yaml\".replace(\"\\\\\", \"/\")\n",
    "with open(config_path, encoding=\"utf-8\") as f:\n",
    "    loaded_config = yaml.load(f, Loader=SafeLoader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import functions from other scripts, these include functions to aggregate, reshape and export the data.\n",
    "#these scripts also include functions to fill newly created geographies and calculate rates and percentages.\n",
    "from function_scripts.export_and_qa import *\n",
    "from function_scripts.update_boundaries import *\n",
    "from function_scripts.metric_calculation import *\n",
    "from function_scripts.reshape_data import *\n",
    "from function_scripts.aggregate_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this line of code creates an output folder within your coding space where outputs will be saved, if one doesn't exist\n",
    "if not os.path.isdir('Outputs'):\n",
    "    os.makedirs('Outputs')\n",
    "    print(\"created folder : \", 'Outputs')\n",
    "else:\n",
    "    print('Outputs', \"folder already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in data using data paths and file names specified in the config\n",
    "#you can change the read function based on your input data file type\n",
    "#the read function replaces common suppression symbols with NAs so numeric operations can be undertaken on the data columns\n",
    "#you may need to add to this list in the config if there is a new suppression symbol in your data\n",
    "datapath = loaded_config[\"lu\"] + loaded_config[\"rawfile\"]\n",
    "raw_data = pd.read_csv(datapath, na_values=loaded_config[\"nalist\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign variable names from the config\n",
    "df_areacode = loaded_config['df_areacode']\n",
    "df_areaname = loaded_config['df_areaname']\n",
    "numerator_column = loaded_config['numerator_column']\n",
    "denominator_column = loaded_config['denominator_column']\n",
    "outname = loaded_config[\"outname\"]\n",
    "keep_variable = loaded_config[\"keep_variable\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unknowns in the area code column\n",
    "#if any other subsetting or data cleaning is required it should be done here\n",
    "#at this stage the dataframe should include the data you want to aggregate and nothing else\n",
    "raw_data = raw_data[raw_data[df_areacode].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset the raw data to include only area name, area code, keep variable and value columns\n",
    "raw_data = raw_data[[df_areacode, \n",
    "                     df_areaname,\n",
    "                     keep_variable, \n",
    "                     numerator_column,\n",
    "                     denominator_column,]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make value columns numeric this must be done at this stage as the next stage involves numeric operations\n",
    "raw_data[numerator_column] = pd.to_numeric(raw_data[numerator_column])\n",
    "raw_data[denominator_column] = pd.to_numeric(raw_data[denominator_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function can be used to generate new geographies if your data does not already include them\n",
    "#it takes the input data, information in the config and uses a lookup to estimate new geography values\n",
    "#this may not be required if all new geographies are present\n",
    "#when using time series data, you need to use the \"keep_column\" version of this function\n",
    "working_data = update_boundaries_keep_column(\n",
    "        df = raw_data,\n",
    "        loaded_config = loaded_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dataset for the geography you are aggregating from with new geographies added\n",
    "#this is exported in the output file for governance\n",
    "lowest_geography_data = working_data.copy(deep=True)\n",
    "\n",
    "#change area code column to consistent \"AREACD\"\n",
    "lowest_geography_data = lowest_geography_data.rename(columns={df_areacode: 'AREACD'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use percentages function to generate value\n",
    "#there is also a function to calculate rates in the metric_calculation script\n",
    "#this takes the data, and columns specified in the loaded config, to generate the variable of interest\n",
    "lowest_geography_data = add_percentages(\n",
    "        data= lowest_geography_data,\n",
    "        loaded_config = loaded_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unstack the data into wide format to make it more readable\n",
    "#this is an optional stage, you may want to keep in a long format if using the data for further coding\n",
    "#if you are using a rate or other value column name, you will need to replace \"percent\" with the new name\n",
    "lowest_geography_data= unstack_multiple_values(\n",
    "    df= lowest_geography_data,\n",
    "    loaded_config = loaded_config,\n",
    "    value_cols= [numerator_column,denominator_column,\"percent\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply the aggregation function, this requires a lookup containing the original geography code \n",
    "#and all other geography codes you wish to aggregate to, you specify these desired geography column names in the config\n",
    "#the function works by merging the lookup to the data and then grouping by each of the new geography columns\n",
    "#it returns 1 dataframe containing all specified geographies\n",
    "#if any underlying data for a larger geography is missing, it will return a missing cell\n",
    "#when using time series data, you need to use the \"keep_column\" version of this function\n",
    "aggregated_data = get_all_desired_geographies_keep_column(\n",
    "        data=working_data,\n",
    "        loaded_config = loaded_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use percentages function to generate value for the aggregated data\n",
    "#there is also a function to calculate rates in the metric_calculation script\n",
    "#this takes the data, and columns specified in the loaded config, to generate the variable of interest\n",
    "aggregated_data = add_percentages(\n",
    "        data= aggregated_data,\n",
    "        loaded_config = loaded_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unstack the data into wide format to make it more readable\n",
    "#this is an optional stage, you may want to keep in a long format if using the data for further coding\n",
    "#if you are using a rate or other value column name, you will need to replace \"percent\" with the new name\n",
    "aggregated_data= unstack_multiple_values(\n",
    "    df= aggregated_data,\n",
    "    loaded_config = loaded_config,\n",
    "    value_cols= [numerator_column,denominator_column,\"percent\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function isolates missing results in your underlying data and merges them to your geography lookup\n",
    "#this provides you with a dataframe including all the missing underlying data and the geographies that\n",
    "#will be missing in your aggregation output\n",
    "missing_geographies = check_missing_geographies(\n",
    "        data= working_data,\n",
    "        loaded_config = loaded_config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function exports your required data in xlsx format into your outputs folder\n",
    "#it is currently set up to export the data you are aggregating, the aggregated data and the missing geographies\n",
    "#output file name can be specified in the config\n",
    "export_to_xlsx(\n",
    "        frames = {'lowest_geography_data': lowest_geography_data, 'aggregated_data': aggregated_data,\n",
    "                  'missing_geographies': missing_geographies}, \n",
    "        file_path = \"Outputs\", \n",
    "        file_name = outname, \n",
    " )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
